{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 1,
>>>>>>> 91da5749a69e2541630e1b4d9fb3619ff3767093
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# for easier reading np\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "with open('./data/nba_games.csv', 'r') as f: \n",
    "  temp = np.genfromtxt(f,delimiter=',', skip_header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split feature matrix and label vector\n",
    "X = temp[:, 1:]\n",
    "y = temp[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training feature matrix: (14305, 24)\n",
      "Size of testing feature matrix: (6131, 24)\n",
      "Size of training label vector: (14305,)\n",
      "Size of testing label vector: (6131,)\n"
     ]
    }
   ],
   "source": [
    "# split training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "print(\"Size of training feature matrix: \"+str(X_train.shape))\n",
    "print(\"Size of testing feature matrix: \"+str(X_test.shape))\n",
    "print(\"Size of training label vector: \"+str(y_train.shape))\n",
    "print(\"Size of testing label vector: \"+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8f/g7qmswr17h3c18qh4m6bbpnh0000gn/T/ipykernel_46219/2594416855.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get pts_home and pts_away columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'list'"
     ]
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FGM_HOME': 0,\n",
       " 'FGA_HOME': 1,\n",
       " 'FG3M_HOME': 2,\n",
       " 'FTM_HOME': 3,\n",
       " 'FTA_HOME': 4,\n",
       " 'OREB_HOME': 5,\n",
       " 'DREB_HOME': 6,\n",
       " 'AST_HOME': 7,\n",
       " 'STL_HOME': 8,\n",
       " 'TOV_HOME': 9,\n",
       " 'PF_HOME': 10,\n",
       " 'PTS_HOME': 11,\n",
       " 'FGM_AWAY': 12,\n",
       " 'FGA_AWAY': 13,\n",
       " 'FG3M_AWAY': 14,\n",
       " 'FTM_AWAY': 15,\n",
       " 'FTA_AWAY': 16,\n",
       " 'OREB_AWAY': 17,\n",
       " 'DREB_AWAY': 18,\n",
       " 'AST_AWAY': 19,\n",
       " 'STL_AWAY': 20,\n",
       " 'TOV_AWAY': 21,\n",
       " 'PF_AWAY': 22,\n",
       " 'PTS_AWAY': 23}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 91da5749a69e2541630e1b4d9fb3619ff3767093
    }
   ],
   "source": [
    "import helper as h\n",
    "col_dict = h.getColDict()\n",
    "col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression on pts_home and pts_away\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# get pts_home and pts_away columns\n",
<<<<<<< HEAD
    "X_train_pts = X_train[:, ~[11, 23]]\n",
    "X_test_pts = X_test[:,~[11,23]]\n",
    "print(X_train_pts)\n",
    "reg = LinearRegression().fit(X_train_pts,y_train)"
=======
    "# col_dict['OREB_HOME'], col_dict['DREB_HOME'], \n",
    "# col_dict['OREB_AWAY'], col_dict['OREB_AWAY'], \n",
    "\n",
    "X_train_pts = X_train[:, [ col_dict['FGA_HOME'], col_dict['DREB_HOME'], col_dict['PTS_HOME'], \n",
    "                          col_dict['FGA_AWAY'], col_dict['OREB_AWAY'], col_dict['PTS_AWAY']]]\n",
    "X_test_pts = X_test[:, [col_dict['FGA_HOME'], col_dict['DREB_HOME'], col_dict['PTS_HOME'], \n",
    "                          col_dict['FGA_AWAY'], col_dict['OREB_AWAY'], col_dict['PTS_AWAY']]]\n",
    "#print(X_train_pts)\n",
    "#reg = LinearRegression().fit(X_train_pts,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82.46341463,  34.29268293, 106.        ,  81.24390244,\n",
       "         10.43902439,  99.68292683],\n",
       "       [ 86.09756098,  33.46341463, 106.92682927,  85.51219512,\n",
       "         10.58536585,  99.97560976],\n",
       "       [ 80.41463415,  30.        ,  84.31707317,  80.02439024,\n",
       "         12.97560976,  94.41463415],\n",
       "       ...,\n",
       "       [ 87.51219512,  35.12195122, 106.87804878,  83.09756098,\n",
       "         11.41463415,  98.46341463],\n",
       "       [ 78.73170732,  34.2195122 ,  98.56097561,  86.31707317,\n",
       "         13.14634146, 110.90243902],\n",
       "       [ 86.18181818,  29.42424242, 100.45454545,  83.15151515,\n",
       "         10.63636364,  96.18181818]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "col_off = 12\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf = clf.fit(X_train_pts, y_train)\n",
    "y_hat = clf.predict(X_test_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1295 1203]\n",
      " [1372 2261]]\n",
      "Accuracy: 58.00%\n"
     ]
    }
   ],
   "source": [
    "# Determine DT performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Cmat = confusion_matrix(y_test, y_hat)\n",
    "acc = clf.score(X_test_pts,y_test)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(Cmat)\n",
    "print(\"Accuracy: \" + str(format(acc*100,'.2f')) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00698635,  0.00986245,  0.00322405,  0.01085739,  0.00194096,\n",
       "        0.00738324,  0.01361387,  0.0206111 ,  0.00446909,  0.00307182,\n",
       "        0.01271679,  0.00957429,  0.00263144,  0.00923177, -0.00058174,\n",
       "        0.00378949,  0.00836731,  0.00667645,  0.02242157,  0.01245039,\n",
       "        0.00444734,  0.00606209,  0.00677432,  0.00550209])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(clf, X_test, y_test,\n",
    "                          n_repeats=30,\n",
    "                          random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'importances_mean': array([ 0.00698635,  0.00986245,  0.00322405,  0.01085739,  0.00194096,\n",
       "         0.00738324,  0.01361387,  0.0206111 ,  0.00446909,  0.00307182,\n",
       "         0.01271679,  0.00957429,  0.00263144,  0.00923177, -0.00058174,\n",
       "         0.00378949,  0.00836731,  0.00667645,  0.02242157,  0.01245039,\n",
       "         0.00444734,  0.00606209,  0.00677432,  0.00550209]),\n",
       " 'importances_std': array([0.00194594, 0.00278069, 0.00158902, 0.00299264, 0.0020273 ,\n",
       "        0.00302719, 0.00348622, 0.00459685, 0.00262615, 0.0021867 ,\n",
       "        0.00312734, 0.00224989, 0.001902  , 0.00197468, 0.0024184 ,\n",
       "        0.00206085, 0.00221413, 0.00217363, 0.00432209, 0.00301086,\n",
       "        0.0023024 , 0.00367599, 0.0030148 , 0.0026134 ]),\n",
       " 'importances': array([[ 0.01043875,  0.00554559,  0.00831838,  0.01043875,  0.01060186,\n",
       "          0.00799217,  0.00668733,  0.00733975,  0.00864459,  0.01092807,\n",
       "          0.00375143,  0.00619801,  0.00538248,  0.00358832,  0.00342522,\n",
       "          0.00570869,  0.00652422,  0.00831838,  0.00636112,  0.00831838,\n",
       "          0.00538248,  0.00750285,  0.00701354,  0.00815528,  0.00685043,\n",
       "          0.00636112,  0.0058718 ,  0.00554559,  0.00668733,  0.00570869],\n",
       "        [ 0.00440385,  0.01223291,  0.01321155,  0.00946012,  0.00815528,\n",
       "          0.00978633,  0.00913391,  0.00685043,  0.0088077 ,  0.0088077 ,\n",
       "          0.01223291,  0.00424074,  0.01125428,  0.01631055,  0.01076496,\n",
       "          0.0088077 ,  0.00848149,  0.01092807,  0.00962323,  0.00717664,\n",
       "          0.0119067 ,  0.00782907,  0.00733975,  0.00946012,  0.01419018,\n",
       "          0.01582124,  0.00929702,  0.01206981,  0.0089708 ,  0.00831838],\n",
       "        [ 0.00424074,  0.00326211,  0.00114174,  0.00163106,  0.00407764,\n",
       "          0.00228348,  0.00212037,  0.00277279,  0.00424074,  0.00538248,\n",
       "          0.00505627,  0.00489317,  0.00212037,  0.00505627,  0.00391453,\n",
       "         -0.00016311,  0.00326211,  0.00195727,  0.00179416,  0.00440385,\n",
       "          0.00228348,  0.00375143,  0.00244658,  0.00554559,  0.00244658,\n",
       "          0.00505627,  0.00195727, -0.00016311,  0.00570869,  0.00424074],\n",
       "        [ 0.00913391,  0.00782907,  0.00946012,  0.00946012,  0.01419018,\n",
       "          0.00913391,  0.00994944,  0.01451639,  0.01092807,  0.01582124,\n",
       "          0.00505627,  0.00929702,  0.00750285,  0.00978633,  0.01288534,\n",
       "          0.0148426 ,  0.01060186,  0.00782907,  0.0058718 ,  0.00782907,\n",
       "          0.00978633,  0.00766596,  0.00929702,  0.0146795 ,  0.01304844,\n",
       "          0.01272223,  0.01337465,  0.01614745,  0.0146795 ,  0.01239602],\n",
       "        [ 0.00179416, -0.00146795,  0.00195727,  0.00358832,  0.00309901,\n",
       "          0.00179416,  0.00163106,  0.00163106,  0.00570869, -0.00114174,\n",
       "          0.00505627,  0.00456695,  0.00195727,  0.00179416,  0.00375143,\n",
       "         -0.00065242,  0.00130484,  0.00048932,  0.00016311,  0.00130484,\n",
       "          0.00521938,  0.00032621,  0.00326211, -0.00114174,  0.00407764,\n",
       "          0.00195727, -0.00016311, -0.00114174,  0.0029359 ,  0.00456695],\n",
       "        [ 0.00815528,  0.0088077 ,  0.00179416,  0.00619801,  0.00619801,\n",
       "          0.0089708 ,  0.00391453,  0.0058718 ,  0.00733975,  0.00570869,\n",
       "          0.0088077 ,  0.00733975,  0.00326211,  0.00570869,  0.0146795 ,\n",
       "          0.01011254,  0.00505627,  0.01141739,  0.00766596,  0.00391453,\n",
       "          0.00946012,  0.00636112,  0.00619801,  0.00424074,  0.00864459,\n",
       "          0.00799217,  0.0088077 ,  0.00342522,  0.0148426 ,  0.01060186],\n",
       "        [ 0.01321155,  0.01288534,  0.01272223,  0.00815528,  0.01223291,\n",
       "          0.01370086,  0.01272223,  0.01435329,  0.0119067 ,  0.00848149,\n",
       "          0.01255913,  0.01516881,  0.01826782,  0.01565813,  0.01598434,\n",
       "          0.00848149,  0.00750285,  0.01859403,  0.01092807,  0.01663676,\n",
       "          0.01337465,  0.02446583,  0.01435329,  0.0146795 ,  0.01304844,\n",
       "          0.01370086,  0.01092807,  0.0117436 ,  0.01908335,  0.01288534],\n",
       "        [ 0.02446583,  0.02560757,  0.02495515,  0.01647366,  0.01027565,\n",
       "          0.02903278,  0.02169304,  0.0205513 ,  0.01859403,  0.02267167,\n",
       "          0.02234546,  0.02528136,  0.02299788,  0.02022509,  0.02006198,\n",
       "          0.0234872 ,  0.02120372,  0.02299788,  0.01239602,  0.02430272,\n",
       "          0.01304844,  0.01712608,  0.01631055,  0.02723862,  0.01712608,\n",
       "          0.01370086,  0.01810471,  0.0205513 ,  0.01843092,  0.02707552],\n",
       "        [ 0.00505627,  0.00799217,  0.00570869,  0.00114174,  0.00391453,\n",
       "          0.00212037,  0.00717664,  0.00521938,  0.00244658,  0.00375143,\n",
       "          0.00701354,  0.00358832,  0.00391453,  0.00326211,  0.00799217,\n",
       "          0.00701354,  0.00391453,  0.00342522,  0.00358832,  0.00244658,\n",
       "          0.00260969,  0.00391453,  0.00440385,  0.00636112,  0.00424074,\n",
       "         -0.00032621,  0.00701354, -0.00260969,  0.01011254,  0.00766596],\n",
       "        [ 0.0029359 ,  0.00032621,  0.00016311,  0.00212037,  0.00391453,\n",
       "          0.00456695,  0.00016311,  0.0058718 ,  0.0060349 ,  0.00652422,\n",
       "          0.00358832,  0.00473006,  0.00065242,  0.00260969,  0.00407764,\n",
       "          0.00081553,  0.00212037,  0.00440385, -0.00081553,  0.00489317,\n",
       "          0.00407764,  0.00114174,  0.00831838,  0.00260969,  0.00375143,\n",
       "          0.00048932,  0.00179416,  0.00114174,  0.00391453,  0.00521938],\n",
       "        [ 0.01272223,  0.01565813,  0.00717664,  0.00913391,  0.00994944,\n",
       "          0.01533192,  0.01125428,  0.0177785 ,  0.01125428,  0.01027565,\n",
       "          0.00978633,  0.01679987,  0.00962323,  0.01272223,  0.01239602,\n",
       "          0.01875714,  0.01451639,  0.01516881,  0.01647366,  0.0117436 ,\n",
       "          0.0148426 ,  0.01875714,  0.00913391,  0.01125428,  0.01027565,\n",
       "          0.01043875,  0.01255913,  0.01321155,  0.0146795 ,  0.00782907],\n",
       "        [ 0.00570869,  0.01370086,  0.00717664,  0.00864459,  0.01027565,\n",
       "          0.01206981,  0.0146795 ,  0.0089708 ,  0.0088077 ,  0.01125428,\n",
       "          0.00521938,  0.01092807,  0.00848149,  0.00962323,  0.01158049,\n",
       "          0.01141739,  0.01060186,  0.00799217,  0.00831838,  0.01011254,\n",
       "          0.0088077 ,  0.0119067 ,  0.00815528,  0.01158049,  0.00864459,\n",
       "          0.00946012,  0.00424074,  0.00913391,  0.01011254,  0.00962323],\n",
       "        [ 0.00016311,  0.00440385,  0.        ,  0.00097863,  0.00309901,\n",
       "          0.00065242,  0.00163106,  0.00048932,  0.00473006,  0.00538248,\n",
       "          0.00407764,  0.00424074,  0.00260969,  0.00342522,  0.00260969,\n",
       "          0.00407764,  0.0029359 ,  0.00260969,  0.00277279,  0.00163106,\n",
       "         -0.00114174,  0.00048932,  0.00065242,  0.00342522,  0.00652422,\n",
       "          0.0058718 ,  0.00016311,  0.00407764,  0.00228348,  0.00407764],\n",
       "        [ 0.0119067 ,  0.00848149,  0.00864459,  0.00864459,  0.00978633,\n",
       "          0.00766596,  0.00505627,  0.00782907,  0.00994944,  0.00554559,\n",
       "          0.00717664,  0.00962323,  0.01239602,  0.01206981,  0.00815528,\n",
       "          0.01158049,  0.00685043,  0.01060186,  0.00733975,  0.00636112,\n",
       "          0.00848149,  0.01011254,  0.00978633,  0.01060186,  0.00978633,\n",
       "          0.01011254,  0.01125428,  0.0119067 ,  0.00766596,  0.01158049],\n",
       "        [-0.00277279, -0.00228348,  0.00130484, -0.00016311,  0.00228348,\n",
       "          0.00081553, -0.00097863,  0.00048932, -0.00081553, -0.00260969,\n",
       "          0.00473006,  0.        , -0.00375143,  0.00130484, -0.00016311,\n",
       "          0.00179416, -0.00309901, -0.00097863, -0.00032621,  0.00032621,\n",
       "         -0.00244658, -0.00228348, -0.00391453, -0.00489317, -0.00097863,\n",
       "         -0.00326211, -0.00097863,  0.00163106, -0.00146795,  0.0060349 ],\n",
       "        [ 0.00212037,  0.00342522,  0.00146795,  0.00521938,  0.00456695,\n",
       "          0.00407764,  0.00391453,  0.00358832,  0.0029359 ,  0.00342522,\n",
       "          0.00750285,  0.        ,  0.00505627,  0.        ,  0.00913391,\n",
       "          0.00407764,  0.00554559,  0.00521938,  0.0029359 ,  0.00342522,\n",
       "          0.00538248,  0.00391453, -0.00081553,  0.00440385,  0.00489317,\n",
       "          0.00260969,  0.00636112,  0.00212037,  0.00309901,  0.00407764],\n",
       "        [ 0.00799217,  0.00831838,  0.00391453,  0.01011254,  0.01011254,\n",
       "          0.00489317,  0.00864459,  0.00685043,  0.00701354,  0.00701354,\n",
       "          0.01076496,  0.00766596,  0.01027565,  0.01043875,  0.00946012,\n",
       "          0.01092807,  0.00375143,  0.00782907,  0.00733975,  0.00489317,\n",
       "          0.00570869,  0.01027565,  0.00962323,  0.00717664,  0.01027565,\n",
       "          0.00994944,  0.00668733,  0.01060186,  0.01027565,  0.01223291],\n",
       "        [ 0.01011254,  0.00668733,  0.00424074,  0.00554559,  0.00750285,\n",
       "          0.00048932,  0.00521938,  0.00929702,  0.0060349 ,  0.00570869,\n",
       "          0.0089708 ,  0.00750285,  0.00538248,  0.0029359 ,  0.00864459,\n",
       "          0.00766596,  0.00994944,  0.00929702,  0.00782907,  0.00570869,\n",
       "          0.00864459,  0.00766596,  0.00701354,  0.00521938,  0.00407764,\n",
       "          0.00456695,  0.00929702,  0.00554559,  0.00619801,  0.00733975],\n",
       "        [ 0.02789105,  0.01402708,  0.0264231 ,  0.02707552,  0.03213179,\n",
       "          0.02104061,  0.02756483,  0.01892024,  0.02821726,  0.02038819,\n",
       "          0.02234546,  0.01598434,  0.01435329,  0.02740173,  0.02544446,\n",
       "          0.02462893,  0.02397651,  0.02413962,  0.02316099,  0.01826782,\n",
       "          0.01712608,  0.02267167,  0.02218235,  0.02136682,  0.01875714,\n",
       "          0.01957266,  0.02185614,  0.02495515,  0.02316099,  0.0176154 ],\n",
       "        [ 0.01533192,  0.00929702,  0.01745229,  0.01223291,  0.00946012,\n",
       "          0.01141739,  0.0148426 ,  0.0058718 ,  0.01109118,  0.01288534,\n",
       "          0.00994944,  0.01125428,  0.0119067 ,  0.0119067 ,  0.01158049,\n",
       "          0.01826782,  0.01516881,  0.01582124,  0.00929702,  0.01370086,\n",
       "          0.01419018,  0.01598434,  0.00848149,  0.01304844,  0.01337465,\n",
       "          0.0089708 ,  0.0177785 ,  0.00799217,  0.01337465,  0.01158049],\n",
       "        [ 0.00473006,  0.0029359 ,  0.00782907, -0.00048932,  0.00636112,\n",
       "          0.00228348,  0.00277279,  0.00489317,  0.00570869,  0.00375143,\n",
       "          0.00473006,  0.00424074,  0.0029359 ,  0.00619801,  0.00473006,\n",
       "          0.0058718 , -0.00065242,  0.00799217,  0.00326211,  0.00962323,\n",
       "          0.00766596,  0.00195727,  0.00277279,  0.00375143,  0.0060349 ,\n",
       "          0.00260969,  0.00277279,  0.00636112,  0.00440385,  0.00538248],\n",
       "        [ 0.0088077 ,  0.00554559,  0.00505627,  0.00929702,  0.00717664,\n",
       "         -0.00032621,  0.00326211,  0.00489317,  0.00782907,  0.00831838,\n",
       "         -0.00309901,  0.00407764,  0.01060186,  0.00163106,  0.00668733,\n",
       "          0.00815528,  0.0058718 ,  0.00717664,  0.00489317,  0.00554559,\n",
       "          0.00342522,  0.00685043,  0.00668733,  0.01109118,  0.00473006,\n",
       "          0.01027565,  0.01565813, -0.00065242,  0.00685043,  0.00554559],\n",
       "        [ 0.00750285,  0.00473006,  0.00489317,  0.01370086,  0.00799217,\n",
       "         -0.00244658,  0.00848149,  0.00733975,  0.00358832,  0.00701354,\n",
       "          0.01141739,  0.00978633,  0.00440385,  0.00636112,  0.00309901,\n",
       "          0.00717664,  0.00391453,  0.00929702,  0.00994944,  0.00815528,\n",
       "          0.00489317,  0.00913391,  0.00326211,  0.00978633,  0.00782907,\n",
       "          0.00456695,  0.00750285,  0.0060349 ,  0.00799217,  0.0058718 ],\n",
       "        [ 0.00570869,  0.00685043,  0.00391453,  0.00929702,  0.00554559,\n",
       "          0.00864459,  0.00929702,  0.00636112,  0.00848149,  0.00195727,\n",
       "         -0.00114174,  0.00864459,  0.00342522,  0.00048932,  0.00521938,\n",
       "          0.00750285,  0.00799217,  0.00473006,  0.00375143,  0.00782907,\n",
       "          0.00652422,  0.00733975,  0.00701354,  0.00358832,  0.00538248,\n",
       "          0.00358832,  0.00097863,  0.00554559,  0.00424074,  0.00636112]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00698635,  0.00986245,  0.00322405,  0.01085739,  0.00194096,\n",
       "        0.00738324,  0.01361387,  0.0206111 ,  0.00446909,  0.00307182,\n",
       "        0.01271679,  0.00957429,  0.00263144,  0.00923177, -0.00058174,\n",
       "        0.00378949,  0.00836731,  0.00667645,  0.02242157,  0.01245039,\n",
       "        0.00444734,  0.00606209,  0.00677432,  0.00550209])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['importances_mean']"
>>>>>>> 91da5749a69e2541630e1b4d9fb3619ff3767093
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.603\n",
      "[[ 319 2154]\n",
      " [ 282 3376]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True).fit(X_train_pts, y_train)\n",
    "y_pred = clf.predict(X_test_pts)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.3f}'.format(accuracy_score(y_pred, y_test)))\n",
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "print(cmat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.675465\n",
      "         Iterations 4\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.001     \n",
      "Dependent Variable: y                AIC:              27609.5872\n",
      "Date:               2022-10-09 15:42 BIC:              27617.5122\n",
      "No. Observations:   20436            Log-Likelihood:   -13804.   \n",
      "Df Model:           0                LL-Null:          -13815.   \n",
      "Df Residuals:       20435            LLR p-value:      nan       \n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     4.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "         Coef.     Std.Err.       z       P>|z|     [0.025    0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1       0.0100      0.0004    26.6406    0.0000    0.0093    0.0107\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X[:,0])\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "097b5c554a4a1fb3c36a4724eac3a26e6c0060d08d435c499edb7301c6a580e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
