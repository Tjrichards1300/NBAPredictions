{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "file_name = \"Rolling15Games.csv\"\n",
    "max_features = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score\n",
    "import itertools\n",
    "\n",
    "# for easier reading np\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "with open(f'../../data/{file_name}', 'r') as f: \n",
    "  temp = np.genfromtxt(f,delimiter=',', skip_header = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split feature matrix and label vector\n",
    "X = temp[:, 1:]\n",
    "y = temp[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training feature matrix: (8161, 24)\n",
      "Size of testing feature matrix: (3498, 24)\n",
      "Size of training label vector: (8161,)\n",
      "Size of testing label vector: (3498,)\n"
     ]
    }
   ],
   "source": [
    "# split training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "print(\"Size of training feature matrix: \"+str(X_train.shape))\n",
    "print(\"Size of testing feature matrix: \"+str(X_test.shape))\n",
    "print(\"Size of training label vector: \"+str(y_train.shape))\n",
    "print(\"Size of testing label vector: \"+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {'FGM_HOME': 0, 'FGA_HOME': 1, 'FG3M_HOME': 2, 'FTM_HOME': 3, 'FTA_HOME': 4, 'OREB_HOME': 5, 'DREB_HOME': 6,\n",
    "            'AST_HOME': 7, 'STL_HOME': 8, 'TOV_HOME': 9, 'PF_HOME': 10, 'PTS_HOME': 11, 'FGM_AWAY': 12, 'FGA_AWAY': 13,\n",
    "            'FG3M_AWAY': 14, 'FTM_AWAY': 15, 'FTA_AWAY': 16, 'OREB_AWAY': 17, 'DREB_AWAY': 18, 'AST_AWAY': 19,\n",
    "            'STL_AWAY': 20, 'TOV_AWAY': 21, 'PF_AWAY': 22, 'PTS_AWAY': 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pts = X_train[:, [ col_dict['FGA_HOME'], col_dict['DREB_HOME'], col_dict['PTS_HOME'], \n",
    "                          col_dict['FGA_AWAY'], col_dict['OREB_AWAY'], col_dict['PTS_AWAY']]]\n",
    "X_test_pts = X_test[:, [col_dict['FGA_HOME'], col_dict['DREB_HOME'], col_dict['PTS_HOME'], \n",
    "                          col_dict['FGA_AWAY'], col_dict['OREB_AWAY'], col_dict['PTS_AWAY']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.615\n",
      "[[ 532  936]\n",
      " [ 412 1618]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True).fit(X_train_pts, y_train)\n",
    "y_pred = clf.predict(X_test_pts)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.3f}'.format(accuracy_score(y_pred, y_test)))\n",
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "print(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Potential Features\n",
    "max_acc = 0\n",
    "max_comb = ()\n",
    "\n",
    "\n",
    "for num_features in range(1,max_features+1):\n",
    "    for comb in itertools.combinations(range(12), num_features):\n",
    "        iter_indices = list(comb)\n",
    "        iter_indices += [i+12 for i in iter_indices]\n",
    "        X_train_pair = X_train[:,iter_indices]\n",
    "        X_test_pair = X_test[:,iter_indices]\n",
    "        clf = LogisticRegression(fit_intercept=True).fit(X_train_pair, y_train)\n",
    "        y_pred = clf.predict(X_test_pair)\n",
    "        iter_acc = accuracy_score(y_pred, y_test)\n",
    "        \n",
    "        if iter_acc > max_acc:\n",
    "            max_comb = comb\n",
    "            max_acc = iter_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy 0.6449399656946827\n",
      "Indices (1, 4, 5, 6, 7, 8, 9, 11)\n",
      "Features ['FGA_HOME', 'FTA_HOME', 'OREB_HOME', 'DREB_HOME', 'AST_HOME', 'STL_HOME', 'TOV_HOME', 'PTS_HOME']\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Accuracy\", max_acc)\n",
    "print(\"Indices\", max_comb)\n",
    "print(\"Features\",[list(col_dict.keys())[i] for i in max_comb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "097b5c554a4a1fb3c36a4724eac3a26e6c0060d08d435c499edb7301c6a580e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
