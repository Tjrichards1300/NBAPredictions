{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "df = pd.read_csv('../../data/LSTMGamesStandardized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_season = 2011\n",
    "# Try with a shorter season\n",
    "df = df[df['SEASON'] >= min_season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>FGM_DIFF</th>\n",
       "      <th>FGA_DIFF</th>\n",
       "      <th>FG3M_DIFF</th>\n",
       "      <th>FTM_DIFF</th>\n",
       "      <th>FTA_DIFF</th>\n",
       "      <th>OREB_DIFF</th>\n",
       "      <th>DREB_DIFF</th>\n",
       "      <th>AST_DIFF</th>\n",
       "      <th>STL_DIFF</th>\n",
       "      <th>TOV_DIFF</th>\n",
       "      <th>PF_DIFF</th>\n",
       "      <th>PTS_DIFF</th>\n",
       "      <th>WIN</th>\n",
       "      <th>HOME_GAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37996</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37997</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-12</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37998</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37999</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38000</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-13</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38001</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38002</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38003</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-12</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38004</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-11</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38005</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-6</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38006</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-7</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38007</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-13</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38008</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38009</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38010</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38011</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>-8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-8</td>\n",
       "      <td>-15</td>\n",
       "      <td>5</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38012</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-6</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38014</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TEAM_ID  FGM_DIFF  FGA_DIFF  FG3M_DIFF  FTM_DIFF  FTA_DIFF  \\\n",
       "37996  1610612766      -1.0        -1         -5       5.0       4.0   \n",
       "37997  1610612766      -8.0        -4         -7      12.0      13.0   \n",
       "37998  1610612766      -3.0        -8         -1       2.0       3.0   \n",
       "37999  1610612766       6.0         8         -1       0.0      -1.0   \n",
       "38000  1610612766      -6.0       -13          3      -1.0       0.0   \n",
       "38001  1610612766      -8.0        -8          5       4.0       4.0   \n",
       "38002  1610612766       0.0        10          5      -4.0      -6.0   \n",
       "38003  1610612766       0.0         3         -2     -15.0     -16.0   \n",
       "38004  1610612766       0.0        -2         -1     -11.0     -12.0   \n",
       "38005  1610612766       5.0        17          1      -5.0      -7.0   \n",
       "38006  1610612766      -8.0        -3         -6       4.0      -1.0   \n",
       "38007  1610612766      -7.0        -3         -2      12.0      16.0   \n",
       "38008  1610612766       4.0        12         -1       0.0      -5.0   \n",
       "38009  1610612766      -4.0        16          7       2.0       4.0   \n",
       "38010  1610612766      -9.0        -3         -3       7.0       5.0   \n",
       "38011  1610612766      -2.0        11         -8       3.0       3.0   \n",
       "38012  1610612766      -2.0         5         -3      13.0      15.0   \n",
       "38013  1610612766       1.0        14          4      -4.0      -6.0   \n",
       "38014  1610612766       4.0        -4          0       5.0       8.0   \n",
       "38015  1610612766      -7.0       -10         -3       9.0       7.0   \n",
       "\n",
       "       OREB_DIFF  DREB_DIFF  AST_DIFF  STL_DIFF  TOV_DIFF  PF_DIFF  PTS_DIFF  \\\n",
       "37996          1         -1        -8        -1        -1     -3.0        -2   \n",
       "37997         -4         -7       -12         4        -3     -7.0       -11   \n",
       "37998          1         10         2        -2         8      0.0        -5   \n",
       "37999          3          0        -3         4        -3      6.0        11   \n",
       "38000         -9         -4        -1        -2         1     -2.0       -10   \n",
       "38001         -7         -4         3        -3         3      3.0        -7   \n",
       "38002          5          1        -4        -1         0     -1.0         1   \n",
       "38003         -8        -12        -2        -5         0      7.0       -17   \n",
       "38004         -5        -11        -2        -3        -2      3.0       -12   \n",
       "38005          7         -6        -7         3        -5      3.0         6   \n",
       "38006         -4         -7       -14         0         1     -2.0       -18   \n",
       "38007          4         -2       -13        -2         2     -5.0        -4   \n",
       "38008          6          0         3        -1        -3      3.0         7   \n",
       "38009         11         -7         3         6        -5      0.0         1   \n",
       "38010         -3         -4        -8         0        -1     -3.0       -14   \n",
       "38011          5         -8       -15         5        -7     -5.0        -9   \n",
       "38012          4         -4        -6         6        -8    -12.0         6   \n",
       "38013          3         -6         1         4        -7      0.0         2   \n",
       "38014        -10         -1         3         2        -2     -5.0        13   \n",
       "38015         -5         -2        -3        -2         2     -5.0        -8   \n",
       "\n",
       "       WIN  HOME_GAME  \n",
       "37996    0          1  \n",
       "37997    0          1  \n",
       "37998    0          1  \n",
       "37999    1          0  \n",
       "38000    0          1  \n",
       "38001    0          1  \n",
       "38002    1          1  \n",
       "38003    0          0  \n",
       "38004    0          0  \n",
       "38005    1          0  \n",
       "38006    0          0  \n",
       "38007    0          1  \n",
       "38008    1          1  \n",
       "38009    1          0  \n",
       "38010    0          0  \n",
       "38011    0          0  \n",
       "38012    1          0  \n",
       "38013    1          1  \n",
       "38014    1          0  \n",
       "38015    0          1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2:].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.80\n",
    "step = 1\n",
    "past = 7\n",
    "future = 0\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 09:52:42.812262: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-14 09:52:42.812580: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "team_list = pd.unique(df['TEAM_ID'])\n",
    "\n",
    "# Create None type for dataset\n",
    "combined_dataset_train = None\n",
    "combined_dataset_val = None\n",
    "\n",
    "for team_id in team_list: \n",
    "    team_df = df[df['TEAM_ID'] == team_id]\n",
    "    \n",
    "    feature_ids = [3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    team_features = team_df.iloc[:,feature_ids]\n",
    "    team_features.index = team_df['GAME_DATE']\n",
    "    team_train_split = int(split_fraction * int(team_df.shape[0]))\n",
    "    \n",
    "    # For now we are normalizing per team\n",
    "    norm_team_features = normalize(team_features.values, team_train_split)\n",
    "    \n",
    "    norm_team_features = pd.DataFrame(norm_team_features)\n",
    "    team_features = pd.DataFrame(team_features.values)\n",
    "    \n",
    "    train_data = norm_team_features.loc[0 : team_train_split - 1]\n",
    "    val_data = norm_team_features.loc[team_train_split:]\n",
    "    \n",
    "    # Create Training Dataset\n",
    "    start = past + future\n",
    "    end = start + team_train_split\n",
    "\n",
    "    x_train = train_data[[i for i in range(len(feature_ids) - 1)]].values\n",
    "    y_train = team_features.iloc[start:end][[12]]\n",
    "\n",
    "    sequence_length = int(past / step)\n",
    "    \n",
    "    dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "    x_end = len(val_data) - past - future\n",
    "\n",
    "    # Validation Dataset now\n",
    "    label_start = team_train_split + past + future\n",
    "\n",
    "    x_val = val_data.iloc[:x_end][[i for i in range(len(feature_ids) - 1)]].values\n",
    "    y_val = team_features.iloc[label_start:][[12]]\n",
    "\n",
    "    \n",
    "    dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        x_val,\n",
    "        y_val,\n",
    "        sequence_length=sequence_length,\n",
    "        sampling_rate=step,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    if combined_dataset_train is None:\n",
    "        combined_dataset_train = dataset_train\n",
    "        combined_dataset_val = dataset_val\n",
    "    else:\n",
    "        combined_dataset_train = dataset_train.concatenate(dataset_train)\n",
    "        combined_dataset_val = combined_dataset_val.concatenate(dataset_val) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 09:52:47.699707: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (256, 7, 12)\n",
      "Target shape: (256, 1)\n",
      "Input shape: (101, 7, 12)\n",
      "Target shape: (101, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in combined_dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n",
    "\n",
    "for batch in combined_dataset_val.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 12)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                5760      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use Keras LSTM layer to consruct a model\n",
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = keras.layers.LSTM(32,dropout=0.5)(inputs)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 09:52:54.016539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-14 09:52:54.213876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 3s - loss: 0.6973 - binary_accuracy: 0.5078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 09:52:54.429890: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.6975 - binary_accuracy: 0.5032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 09:52:55.256298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-14 09:52:55.320319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_binary_accuracy improved from -inf to 0.53626, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 3s 620ms/step - loss: 0.6975 - binary_accuracy: 0.5032 - val_loss: 0.6901 - val_binary_accuracy: 0.5363\n",
      "Epoch 2/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6820 - binary_accuracy: 0.5885\n",
      "Epoch 2: val_binary_accuracy improved from 0.53626 to 0.54803, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6859 - binary_accuracy: 0.5698 - val_loss: 0.6874 - val_binary_accuracy: 0.5480\n",
      "Epoch 3/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6710 - binary_accuracy: 0.6283\n",
      "Epoch 3: val_binary_accuracy improved from 0.54803 to 0.55121, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.6763 - binary_accuracy: 0.6036 - val_loss: 0.6855 - val_binary_accuracy: 0.5512\n",
      "Epoch 4/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6606 - binary_accuracy: 0.6433\n",
      "Epoch 4: val_binary_accuracy improved from 0.55121 to 0.55216, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.6673 - binary_accuracy: 0.6195 - val_loss: 0.6843 - val_binary_accuracy: 0.5522\n",
      "Epoch 5/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6508 - binary_accuracy: 0.6543\n",
      "Epoch 5: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.6588 - binary_accuracy: 0.6321 - val_loss: 0.6838 - val_binary_accuracy: 0.5499\n",
      "Epoch 6/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6415 - binary_accuracy: 0.6598\n",
      "Epoch 6: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.6507 - binary_accuracy: 0.6459 - val_loss: 0.6841 - val_binary_accuracy: 0.5503\n",
      "Epoch 7/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6327 - binary_accuracy: 0.6667\n",
      "Epoch 7: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.6431 - binary_accuracy: 0.6501 - val_loss: 0.6852 - val_binary_accuracy: 0.5468\n",
      "Epoch 8/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6244 - binary_accuracy: 0.6694\n",
      "Epoch 8: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.6359 - binary_accuracy: 0.6564 - val_loss: 0.6873 - val_binary_accuracy: 0.5477\n",
      "Epoch 9/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6166 - binary_accuracy: 0.6735\n",
      "Epoch 9: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6292 - binary_accuracy: 0.6586 - val_loss: 0.6902 - val_binary_accuracy: 0.5487\n",
      "Epoch 10/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6095 - binary_accuracy: 0.6763\n",
      "Epoch 10: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6229 - binary_accuracy: 0.6617 - val_loss: 0.6941 - val_binary_accuracy: 0.5477\n",
      "Epoch 11/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.6790\n",
      "Epoch 11: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.6172 - binary_accuracy: 0.6638 - val_loss: 0.6986 - val_binary_accuracy: 0.5483\n",
      "Epoch 12/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5970 - binary_accuracy: 0.6872\n",
      "Epoch 12: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.6119 - binary_accuracy: 0.6702 - val_loss: 0.7037 - val_binary_accuracy: 0.5512\n",
      "Epoch 13/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5916 - binary_accuracy: 0.6886\n",
      "Epoch 13: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.6070 - binary_accuracy: 0.6723 - val_loss: 0.7088 - val_binary_accuracy: 0.5499\n",
      "Epoch 14/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5867 - binary_accuracy: 0.6872\n",
      "Epoch 14: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6023 - binary_accuracy: 0.6734 - val_loss: 0.7135 - val_binary_accuracy: 0.5477\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.6765\n",
      "Epoch 15: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.5978 - binary_accuracy: 0.6765 - val_loss: 0.7174 - val_binary_accuracy: 0.5493\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5933 - binary_accuracy: 0.6786\n",
      "Epoch 16: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5933 - binary_accuracy: 0.6786 - val_loss: 0.7203 - val_binary_accuracy: 0.5503\n",
      "Epoch 17/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5730 - binary_accuracy: 0.6941\n",
      "Epoch 17: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5886 - binary_accuracy: 0.6808 - val_loss: 0.7224 - val_binary_accuracy: 0.5512\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5839 - binary_accuracy: 0.6797\n",
      "Epoch 18: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5839 - binary_accuracy: 0.6797 - val_loss: 0.7238 - val_binary_accuracy: 0.5515\n",
      "Epoch 19/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5638 - binary_accuracy: 0.6982\n",
      "Epoch 19: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.5790 - binary_accuracy: 0.6871 - val_loss: 0.7250 - val_binary_accuracy: 0.5503\n",
      "Epoch 20/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5590 - binary_accuracy: 0.7010\n",
      "Epoch 20: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5739 - binary_accuracy: 0.6913 - val_loss: 0.7263 - val_binary_accuracy: 0.5515\n",
      "Epoch 21/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5541 - binary_accuracy: 0.7092\n",
      "Epoch 21: val_binary_accuracy did not improve from 0.55216\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.5687 - binary_accuracy: 0.6987 - val_loss: 0.7279 - val_binary_accuracy: 0.5515\n",
      "Epoch 22/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5490 - binary_accuracy: 0.7106\n",
      "Epoch 22: val_binary_accuracy improved from 0.55216 to 0.55280, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.5633 - binary_accuracy: 0.7030 - val_loss: 0.7301 - val_binary_accuracy: 0.5528\n",
      "Epoch 23/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5436 - binary_accuracy: 0.7174\n",
      "Epoch 23: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.5577 - binary_accuracy: 0.7082 - val_loss: 0.7329 - val_binary_accuracy: 0.5522\n",
      "Epoch 24/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5381 - binary_accuracy: 0.7243\n",
      "Epoch 24: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.5518 - binary_accuracy: 0.7199 - val_loss: 0.7361 - val_binary_accuracy: 0.5490\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5456 - binary_accuracy: 0.7326\n",
      "Epoch 25: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5456 - binary_accuracy: 0.7326 - val_loss: 0.7395 - val_binary_accuracy: 0.5493\n",
      "Epoch 26/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5263 - binary_accuracy: 0.7449\n",
      "Epoch 26: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.5392 - binary_accuracy: 0.7421 - val_loss: 0.7432 - val_binary_accuracy: 0.5490\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5324 - binary_accuracy: 0.7442\n",
      "Epoch 27: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.5324 - binary_accuracy: 0.7442 - val_loss: 0.7468 - val_binary_accuracy: 0.5461\n",
      "Epoch 28/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5134 - binary_accuracy: 0.7517\n",
      "Epoch 28: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.5254 - binary_accuracy: 0.7495 - val_loss: 0.7504 - val_binary_accuracy: 0.5474\n",
      "Epoch 29/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5065 - binary_accuracy: 0.7613\n",
      "Epoch 29: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5180 - binary_accuracy: 0.7579 - val_loss: 0.7541 - val_binary_accuracy: 0.5493\n",
      "Epoch 30/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4993 - binary_accuracy: 0.7654\n",
      "Epoch 30: val_binary_accuracy did not improve from 0.55280\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.5102 - binary_accuracy: 0.7632 - val_loss: 0.7582 - val_binary_accuracy: 0.5515\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5022 - binary_accuracy: 0.7674\n",
      "Epoch 31: val_binary_accuracy improved from 0.55280 to 0.55344, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.5022 - binary_accuracy: 0.7674 - val_loss: 0.7627 - val_binary_accuracy: 0.5534\n",
      "Epoch 32/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4839 - binary_accuracy: 0.7805\n",
      "Epoch 32: val_binary_accuracy improved from 0.55344 to 0.55439, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4938 - binary_accuracy: 0.7780 - val_loss: 0.7678 - val_binary_accuracy: 0.5544\n",
      "Epoch 33/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4757 - binary_accuracy: 0.7819\n",
      "Epoch 33: val_binary_accuracy improved from 0.55439 to 0.55821, saving model to model_checkpoint.h5\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4850 - binary_accuracy: 0.7801 - val_loss: 0.7732 - val_binary_accuracy: 0.5582\n",
      "Epoch 34/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4672 - binary_accuracy: 0.7833\n",
      "Epoch 34: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4759 - binary_accuracy: 0.7854 - val_loss: 0.7790 - val_binary_accuracy: 0.5560\n",
      "Epoch 35/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4583 - binary_accuracy: 0.7929\n",
      "Epoch 35: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4664 - binary_accuracy: 0.7928 - val_loss: 0.7851 - val_binary_accuracy: 0.5560\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4566 - binary_accuracy: 0.7949\n",
      "Epoch 36: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4566 - binary_accuracy: 0.7949 - val_loss: 0.7915 - val_binary_accuracy: 0.5525\n",
      "Epoch 37/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4394 - binary_accuracy: 0.7970\n",
      "Epoch 37: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4464 - binary_accuracy: 0.7981 - val_loss: 0.7984 - val_binary_accuracy: 0.5550\n",
      "Epoch 38/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4294 - binary_accuracy: 0.7984\n",
      "Epoch 38: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.4359 - binary_accuracy: 0.7992 - val_loss: 0.8059 - val_binary_accuracy: 0.5534\n",
      "Epoch 39/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4190 - binary_accuracy: 0.8038\n",
      "Epoch 39: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.4250 - binary_accuracy: 0.8066 - val_loss: 0.8140 - val_binary_accuracy: 0.5512\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4138 - binary_accuracy: 0.8203\n",
      "Epoch 40: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4138 - binary_accuracy: 0.8203 - val_loss: 0.8228 - val_binary_accuracy: 0.5515\n",
      "Epoch 41/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3971 - binary_accuracy: 0.8299\n",
      "Epoch 41: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4022 - binary_accuracy: 0.8319 - val_loss: 0.8324 - val_binary_accuracy: 0.5518\n",
      "Epoch 42/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3856 - binary_accuracy: 0.8395\n",
      "Epoch 42: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.3902 - binary_accuracy: 0.8393 - val_loss: 0.8432 - val_binary_accuracy: 0.5474\n",
      "Epoch 43/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3738 - binary_accuracy: 0.8491\n",
      "Epoch 43: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.3779 - binary_accuracy: 0.8488 - val_loss: 0.8552 - val_binary_accuracy: 0.5480\n",
      "Epoch 44/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3616 - binary_accuracy: 0.8519\n",
      "Epoch 44: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.3653 - binary_accuracy: 0.8573 - val_loss: 0.8687 - val_binary_accuracy: 0.5493\n",
      "Epoch 45/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3491 - binary_accuracy: 0.8615\n",
      "Epoch 45: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.3525 - binary_accuracy: 0.8658 - val_loss: 0.8837 - val_binary_accuracy: 0.5512\n",
      "Epoch 46/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3362 - binary_accuracy: 0.8656\n",
      "Epoch 46: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.3393 - binary_accuracy: 0.8710 - val_loss: 0.9006 - val_binary_accuracy: 0.5525\n",
      "Epoch 47/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3232 - binary_accuracy: 0.8697\n",
      "Epoch 47: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.3259 - binary_accuracy: 0.8774 - val_loss: 0.9193 - val_binary_accuracy: 0.5499\n",
      "Epoch 48/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3099 - binary_accuracy: 0.8807\n",
      "Epoch 48: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.3123 - binary_accuracy: 0.8890 - val_loss: 0.9403 - val_binary_accuracy: 0.5483\n",
      "Epoch 49/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2965 - binary_accuracy: 0.8930\n",
      "Epoch 49: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.2986 - binary_accuracy: 0.9017 - val_loss: 0.9633 - val_binary_accuracy: 0.5448\n",
      "Epoch 50/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2831 - binary_accuracy: 0.9053\n",
      "Epoch 50: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.2850 - binary_accuracy: 0.9123 - val_loss: 0.9883 - val_binary_accuracy: 0.5452\n",
      "Epoch 51/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2697 - binary_accuracy: 0.9095\n",
      "Epoch 51: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.2713 - binary_accuracy: 0.9165 - val_loss: 1.0147 - val_binary_accuracy: 0.5458\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2578 - binary_accuracy: 0.9239\n",
      "Epoch 52: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.2578 - binary_accuracy: 0.9239 - val_loss: 1.0426 - val_binary_accuracy: 0.5426\n",
      "Epoch 53/100\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2433 - binary_accuracy: 0.9204\n",
      "Epoch 53: val_binary_accuracy did not improve from 0.55821\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.2445 - binary_accuracy: 0.9260 - val_loss: 1.0722 - val_binary_accuracy: 0.5461\n"
     ]
    }
   ],
   "source": [
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", min_delta=0, patience=20)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_binary_accuracy\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    combined_dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=combined_dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def visualize_loss(history, title):\n",
    "    accuracy = history.history[\"binary_accuracy\"]\n",
    "    val_accuracy = history.history[\"val_binary_accuracy\"]\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, \"b\", label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, \"r\", label=\"Validation Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 12:57:15.578676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-12-08 12:57:15.636197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6843516]\n",
      "tf.Tensor([0.], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset_val.take(1):\n",
    "    print(model.predict(x)[2])\n",
    "    print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_checkpoint.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = None\n",
    "y_true = None\n",
    "for x,y in combined_dataset_val:\n",
    "    temp_pred = np.rint(model.predict(x)).flatten()\n",
    "    temp_y = y.numpy().flatten()\n",
    "    if y_pred is None:\n",
    "        y_pred = temp_pred\n",
    "        y_true = y\n",
    "    else:\n",
    "        y_pred = np.append(y_pred,temp_pred)\n",
    "        y_true = np.append(y_true,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1143,  424],\n",
       "       [ 965,  612]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.99609667  0.3195222  -0.58107665 -0.72899701 -0.57729918  1.30514796\n",
      "   1.02195905  1.23214668 -0.82500226  0.97228962  0.50215437  0.31415629]\n",
      " [ 0.8350672   0.54727686  1.62094642 -2.09035986 -1.70643885  1.86516516\n",
      "   1.97698378  0.77977193 -0.5459231   2.69401505  1.52308792  0.17063615]\n",
      " [-0.77522744 -0.02210979 -1.24168357 -0.32058816 -1.02895504 -0.37490365\n",
      "  -0.61522619 -0.27576916  0.84947266  0.11142691  1.93146134 -1.26456522]\n",
      " [-1.74140423  1.4582955   0.07953027 -1.95422357 -1.48061091  1.11847556\n",
      "  -1.57025091 -1.63289342 -0.26684395  0.32664258  0.91052779 -2.55624645]\n",
      " [-0.45316851  0.09176754 -1.02148127 -0.04831559 -1.14186901  0.18511355\n",
      "   0.74909485 -0.42656074 -1.94131887  0.97228962  1.1147145  -0.76224474]\n",
      " [ 1.15712613  0.09176754 -0.58107665 -0.04831559 -0.23855727 -0.74824846\n",
      "   0.33979854  1.53372985  0.29131436 -0.53422013 -0.31459247  0.81647677]\n",
      " [ 0.02991988 -0.81925111  0.29973258 -0.59286073 -0.69021314 -0.56157606\n",
      "   0.20336643 -0.57735233 -0.82500226  0.11142691  0.91052779 -0.18816419]], shape=(7, 12), dtype=float64)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for x,y in combined_dataset_train.take(1):\n",
    "    print(x[0])\n",
    "    print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "467d3a509279e4a76cca96fb79aa700ee433e3572db510304c3a649513a5acec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
